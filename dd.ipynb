{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "records =[]\n",
    "allrecords = [] \n",
    "allkeys =[] \n",
    "test= []\n",
    "summaryall=[]\n",
    "clean_data=[]\n",
    "clean_data1=[]\n",
    "main_words=[]\n",
    "all_words1=[]\n",
    "all_words2=[]\n",
    "testrecords=[]\n",
    "testsummary=[]\n",
    "all_words3=[]\n",
    "XY= pd.read_csv('RAW_DATA.csv')\n",
    "data = XY[\"DATA\"]\n",
    "labels = XY[\"CATEGORIES\"]\n",
    "labels_index = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(XY.CATEGORIES.unique()):\n",
    "    labels_index[i] = idx\n",
    "cachedStopWords = set(stopwords.words(\"english\"))\n",
    "cachedStopWords.update(('english',':','?','\\b0','\\f0','-','arial','cell','caller','default','paragraph','-','follow -up','@',';','by:','xxxx-xxxx','details',',','patient','call','additional','{','}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in data[:13000]:\n",
    "    message = re.sub(r\"([\\\\])(\\w+)\\b\",r\" \",x)\n",
    "    message= re.sub(r\"\\w*\\d\\w*\",r\" \", message)\n",
    "    message = re.sub(' +',' ',message)\n",
    "    message=re.sub(r\"^(?:(?:[0-9]{2}[:\\/,]){2}[0-9]{2,4}|am|pm)$\",r\" \",message)\n",
    "    regex = re.compile(r'''\n",
    "    [\\S]+:                # a key (any word followed by a colon)\n",
    "    (?:\n",
    "    \\s                    # then a space in between\n",
    "        (?!\\S+:)\\S+       # then a value (any word not followed by a colon)\n",
    "    )+                    # match multiple values if present\n",
    "    ''', re.VERBOSE)\n",
    "    \n",
    "    matches = regex.findall(message)\n",
    "    allrecords.append(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listclean=list(map(''.join, allrecords))\n",
    "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
    "sklearn_representation = sklearn_tfidf.fit_transform(listclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 32290)\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "print(sklearn_representation.shape)\n",
    "category=XY.CATEGORIES[:13000]\n",
    "print(len(category))\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [labels_index[label] for label in category]\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=sklearn_representation.shape[1]))\n",
    "model.add(Dense(len(labels_index), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11700 samples, validate on 1300 samples\n",
      "Epoch 1/2\n",
      "11700/11700 [==============================] - 140s 12ms/step - loss: 1.4368 - acc: 0.5929 - val_loss: 0.9923 - val_acc: 0.6769\n",
      "Epoch 2/2\n",
      "11700/11700 [==============================] - 119s 10ms/step - loss: 0.5435 - acc: 0.8462 - val_loss: 0.9646 - val_acc: 0.6862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1328e6d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(sklearn_representation.todense(), labels, validation_split=0.1, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(500,), max_iter=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(sklearn_representation.todense(), labels)\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_score(clf.predict(sklearn_representation.todense()), labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
